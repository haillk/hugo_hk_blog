---
title: 'AttentionGAN'
tags: 
-
categories: 
- 机器学习
date: "2020-03-29T00:18:57+08:00"
comment:  true    
---

*

<!--more-->

### 论文解读：

```python
背景：
	基于cycleGAN，存在Gx->y  Dy 和 Gy->x Dx
注意引导生成器方案一：
	通过带有注意力机制的两个生成器，
    	Gx->y:   x->[Ay,Cy]->Gy
        Gy->x:   y->[Ax,Cx]->Gx
        (Ax和Ay是图片x和y的注意力蒙版)
        (Cx和Cy是图片x和y的内容蒙版)
        (Gx,Gy是生成的图像)
        注意力蒙版Ax和Ay定义每个像素强度，该强度指定内容蒙版Cx和Cy的每个像素在最终渲染的图像中所起的作用。
        通过这种方法，生成器不需要渲染静态元素，可以只关注定义域内移动的像素
        之后我们将输入的图像x和注意力蒙版Ay和内容蒙版Cy三者融合在一起得到Gy
        
        大体流程：
        	输入一个三通道的图片，输出A和C：
            	x:h*w*3--->A:h*w + C:h*w*3
            得到最后方程：
            	Gy=Cy*Ay+x*(1-Ay) --------------(1)其中前者是注意区域，后者是北京区域
     方案一在面部表情到表情的翻译上表现很好，但是无法在马到斑马上表现初测。
    缺点有：1、Ay和Cy在同一网络生成；
    		2、仅产生一个Ay;
        	3、仅生成一个Cy
注意引导生成器方案二：
	方案er中每个生成器由两个子网落组成，分别生成Ay和Cy
    生成器Gx->组成：
    	一个参数共享encoderEx->y:
            目的是提取底层和高层深度特征表示
        一个注意力蒙版生成器GAx->y：
        	生成多个注意力蒙版
        一个内容蒙版生成器GCx->y
        	生成多个中间内容蒙版
    解决了缺点1：这样Ay和Cy都有各自的网络参数，不会相互干扰。
    
    注意力蒙版：GAx-y生成(n-1)个前景关注蒙版Afy，和一个背景关注蒙版Aby。这样网络可以同时学习新颖的前景并保留背景。
    内容蒙版：内容蒙版生成器生成(n-1)个内容蒙版。然后和x加到一起，就有n个中间内容蒙版。这个方法中3通道生成空间被扩大到3*n通道生成空间，这有利于学习复杂的图像。
    最后方程为：Gy=求和（Cy*Afy）+x*Aby

循环一致性。
    。。。跟cycle差不多，，，
    
判别器：
	对抗损失
    注意力引导对抗损失Lagan
    注意力损失
    像素损失
    全连接损失     
```

### 代码理解：

```python

```

